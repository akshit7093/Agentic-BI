# Agentic MMM System v2.0

A fully agentic, intelligent Marketing Mix Modelling (MMM) system built on LangGraph + Databricks. The agent autonomously profiles data, engineers features, fits probabilistic models, optimises budgets, and can create its own tools on-the-fly.

---

## Architecture

```
agentic_mmm/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ config.py                    â† Centralised configuration
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ mmm_engine.py            â† Data loading, profiling, modelling, optimisation
â”‚   â”œâ”€â”€ transforms.py            â† Adstock, Hill, saturation transforms
â”‚   â””â”€â”€ executor.py              â† Sandboxed Python execution
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ registry.py              â† Dynamic tool registry (add tools at runtime)
â”‚   â”œâ”€â”€ data_tools.py            â† Load, inspect, EDA, transform tools
â”‚   â”œâ”€â”€ mmm_tools.py             â† Adstock opt, OLS/Bayesian MMM, budget opt
â”‚   â””â”€â”€ custom_tools.py          â† Meta-tools: create tools, ask user, log notes
â”‚
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ state.py                 â† AgentState, Phase enum, phase transitions
â”‚   â””â”€â”€ nodes.py                 â† agent_node, tool_node, router
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ prompts.py               â† Dynamic system prompt (phase-aware)
â”‚   â””â”€â”€ builder.py               â† Assemble LangGraph graph
â”‚
â””â”€â”€ main.py                      â† NotebookMMM entry point, init_mmm()
```

---

## Quick Start

```python
from agentic_mmm import init_mmm

# Initialise with a Databricks Unity Catalog table
nb = init_mmm(
    table="catalog.schema.mmm_weekly_spend",
    kpi_col="revenue",
    llm_endpoint="databricks-llama-4-maverick",
)

# One-shot questions
nb.ask("Profile this dataset and tell me if it's suitable for MMM")
nb.ask("Which channels have the highest ROI?")
nb.ask("Optimise my $500,000 monthly budget across all channels")

# Full autonomous end-to-end analysis
nb.run_full_analysis(kpi_col="revenue")

# Interactive chat loop
nb.chat()
```

---

## Key Features

### ğŸ§  Intelligent Data Profiling
The agent automatically:
- Detects spend, KPI, datetime, and channel columns by keyword matching
- Checks data quality (nulls, outliers, skewness)
- Determines if aggregation is needed (transaction â†’ weekly time series)
- Warns if data volume is insufficient for reliable MMM

### âš™ï¸ Dynamic Workflow Phases
The agent moves through defined phases autonomously:
```
IDLE â†’ DATA_LOADING â†’ DATA_PROFILING â†’ DATA_VALIDATION â†’
FEATURE_ENGINEERING â†’ ADSTOCK_OPTIMISATION â†’ MODELING â†’
EVALUATION â†’ BUDGET_OPTIMISATION â†’ REPORTING
```
Each phase has specific guidance injected into the system prompt.

### ğŸ”§ On-the-Run Custom Tools
The agent can CREATE new tools mid-analysis:

```python
# Agent creates this autonomously, OR you create it manually:
nb.add_tool(
    name="detect_seasonality",
    description="Test for weekly/monthly seasonality using autocorrelation",
    code="""
def tool_fn(column, lags=52):
    import json, numpy as np
    from pandas import Series
    s = df[column].values
    acf = [np.corrcoef(s[:-lag], s[lag:])[0, 1] for lag in range(1, lags+1)]
    peak_lag = int(np.argmax(np.abs(acf))) + 1
    return json.dumps({
        "peak_autocorrelation_lag": peak_lag,
        "peak_acf_value": round(acf[peak_lag-1], 4),
        "likely_seasonality": f"{peak_lag}-period cycle"
    })
""",
    params={"column": "str", "lags": "int"},
)
```

### ğŸ“Š Probabilistic Modelling
- **OLS/Ridge**: Fast iteration (no PyMC required)
- **Bayesian MMM (PyMC)**: Full posterior distributions, uncertainty quantification
- **Adstock optimisation**: Grid-search + scipy for decay, half-saturation, slope
- **Budget optimisation**: Differential evolution + SLSQP for revenue maximisation

### ğŸ—£ï¸ User Interaction
The agent asks smart questions when genuinely needed:
- Column disambiguation
- Budget parameters
- Model selection (OLS vs Bayesian)
- Confirmation before expensive MCMC runs

---

## Configuration (`config.py`)

```python
from agentic_mmm.config import LLM_CFG, AGENT_CFG

LLM_CFG.endpoint = "databricks-claude-3-5-sonnet"
LLM_CFG.temperature = 0.1
LLM_CFG.max_agent_steps = 30
AGENT_CFG.min_rows_for_mmm = 104  # require 2 years of weekly data
```

---

## Direct Engine Access (no agent)

```python
from agentic_mmm.core.mmm_engine import MMMEngine

engine = MMMEngine()
engine.load_data("catalog.schema.spend_data")
print(engine.get_column_stats("tv_spend"))
print(engine.optimize_adstock_parameters("tv_spend", "revenue"))
print(engine.run_ols_mmm("revenue", ["tv_spend", "digital_spend", "radio_spend"]))
print(engine.optimize_budget(1_000_000, ["tv_spend", "digital_spend", "radio_spend"]))
```

---

## Supported Data Sources

| Format | Example |
|--------|---------|
| Unity Catalog | `catalog.schema.table` |
| CSV | `/dbfs/mnt/data/mmm.csv` |
| Parquet | `/dbfs/mnt/data/mmm.parquet` |
| Excel | `/dbfs/mnt/data/mmm.xlsx` |
| JSON | `/dbfs/mnt/data/mmm.json` |

---

## Available Tools (37 total)

### Data Tools
| Tool | Description |
|------|-------------|
| `get_data_status` | Check data load state |
| `load_data` | Load from any source |
| `inspect_data` | Full profile with EDA |
| `get_column_stats` | Per-column statistics |
| `get_top_values` | Top N with groupby |
| `sample_rows` | Random sample |
| `filter_aggregate` | Filter + agg |
| `get_correlation_matrix` | Pearson correlation |
| `detect_outliers` | IQR / Z-score |
| `execute_query` | Custom pandas code |
| `clean_data` | Remove nulls/dupes |
| `add_time_features` | Week/month/quarter |
| `aggregate_weekly` | Resample to weekly |

### MMM Tools
| Tool | Description |
|------|-------------|
| `get_adstock_recommendations` | Column suitability analysis |
| `optimize_adstock_parameters` | Single channel decay/hill opt |
| `optimize_all_adstock_parameters` | All channels at once |
| `run_ols_mmm` | Fast Ridge regression MMM |
| `run_bayesian_mmm` | Full Bayesian MMM (PyMC) |
| `roi_summary` | Ranked ROI table |
| `optimize_budget` | Revenue-maximising allocation |
| `simulate_scenario` | Custom budget scenario |
| `compare_scenarios` | A/B budget comparison |

### Meta Tools (Agent Self-Extension)
| Tool | Description |
|------|-------------|
| `create_custom_tool` | Build a new tool on the fly |
| `list_custom_tools` | See all dynamic tools |
| `inspect_custom_tool` | View tool source code |
| `remove_custom_tool` | Remove a dynamic tool |
| `ask_user` | Get user clarification |
| `ask_user_to_choose` | Present options to user |
| `add_analysis_note` | Log insight to history |
| `get_analysis_history` | Review all logged notes |
| `list_all_tools` | Full tool inventory |

---

## Installation

```bash
pip install langgraph langchain-core databricks-langchain \
            pandas numpy scipy scikit-learn rich pydantic \
            pymc arviz  # optional for Bayesian modelling
```

---

## Environment Variables

```bash
export DATABRICKS_HOST=https://your-workspace.azuredatabricks.net
export DATABRICKS_TOKEN=dapi...
```

Or set in notebook:
```python
import os
os.environ["DATABRICKS_HOST"] = "https://..."
os.environ["DATABRICKS_TOKEN"] = "dapi..."
```
